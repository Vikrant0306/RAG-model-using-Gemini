{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "454a421b",
   "metadata": {},
   "outputs": [],
   "source": [
    " from langchain_community.document_loaders import PyPDFLoader\n",
    " loader= PyPDFLoader(\"Image_Processing_Technology_Based_on_Machine_Learning.pdf\")\n",
    " data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc58900f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae7369d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Microsoft® Word 2013; modified using iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'Appligent AppendPDF Pro 5.5', 'creationdate': '2022-02-11T10:30:48-05:00', 'moddate': '2022-02-11T11:27:56-05:00', 'ieee article id': '9712416', 'ieee issue id': '9085929', 'subject': 'IEEE Consumer Electronics Magazine; ;PP;99;10.1109/MCE.2022.3150659', 'ieee publication id': '5962380', 'title': 'Image Processing Technology Based on Machine Learning', 'appligent': 'AppendPDF Pro 5.5 Linux Kernel 2.6 64bit Oct  2 2014 Library 10.1.0', 'source': 'Image_Processing_Technology_Based_on_Machine_Learning.pdf', 'total_pages': 6, 'page': 0, 'page_label': '1'}, page_content=\"2162-2248 (c) 2021 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.\\nThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/MCE.2022.3150659, IEEE\\nConsumer Electronics Magazine\\nImage Processing Technology Based on Machine \\nLearning \\nQiong Qiao1,a* \\n1 School of Information and Communication Engineering, Communication University of China, Beijing 100024, \\nChina \\n*Corresponding author aE-mail: qqthefirst@cuc.edu.cn \\n \\nAbstract—Machine learning is a relatively new field. With \\nthe deepening of people's research in this field, the application \\nof machine learning is increasingly extensive. On the other \\nhand, with the advancement of science and technology, \\ngraphics have been the an indispensable medium of \\ninformation transmission, and image processing technology is \\nalso booming. However, the traditional image processing \\ntechnology, more or less has some defects, this paper \\nintroduces machine learning into image processing, and \\nstudies the image processing technology based on machine \\nlearning. This paper summarizes the current popular image \\nprocessing technology, compares various image technology in \\ndetail, and explains the limitations of each image processing \\nmethod. In addition, on the basis of image processing, this \\npaper introduces machine learning algorithm, applies \\nconvolution neural network to feature extraction of image \\nprocessing, and carries out simulation test. In the test, we \\nselect voc2007 dataset for image segmentation, Imagenet \\ndataset for target detection, cifar100 dataset for image \\nclassification, and ROC curve for performance evaluation. \\nThe results show that the algorithm based on deep learning \\ncan achieve high accuracy in image segmentation, \\nclassification and target detection. The accuracy of image \\nsegmentation is 0.984, the accuracy of image classification is \\n0.987, and the accuracy of target detection is 0.986. Thus, \\nimage processing based on machine learning has great \\nadvantages. \\n \\nIndex Terms —Machine learning, Image Processing, \\nConvolution Neural Network, Feature Extraction \\nI. INTRODUCTION \\nFor image extraction useful information has become \\nvital, and image processing technology has become vital. \\nImage processing technology has been widely used in \\nvarious fields, including video surveillance, automatic \\nvehicle driving, industrial defect detection, agriculture, \\ntransportation, medicine, military and other fields [1]. \\nFollowing the growth of science and technology, machine \\ntraining techniques have rapidly returned to the forefront of \\npeople's minds. Machine learning technology provides \\nconvenience for many aspects of modern society. \\nDigital picture processing is now widely used. Due to the \\nsignificance of picture handling skills, there has been a \\ngreat advancement in image processing technology. Z. Zhu \\net al. [2] suggested a new multimodal approach to image \\nmerging based on image factorization and thin presentation, \\nwhich can effectively fuse images. L. Mauryaa et al. [3-4] \\nproposed a social spider optimized image fusion method, \\nwhich can increase contrast while maintaining brightness \\nwhile fusing images.K. Li et al. [5] used multi-peak feature \\nfusion for map labeling, which can effectively improve \\nlabeling accuracy. Montesinos et al. [6] use Bayesian \\nnetwork to classify images, and the classification accuracy \\ncan be more than 90%. Singh et al. [7] used genetic \\nalgorithm to train genetic function network and then used \\nthe trained model for satellite video categorization, which \\nsolved the problem of inaccurate satellite image \\ncategorization. Maa et al. [8] analyzed an object-based \\nsupervised land cover image classification algorithm. Liu et \\nal. [9] used polyscale depth functions to classify scenes \\nfrom satellite images at high resolution, and the simulation \\naccuracy was significantly improved. D. Meraa et al. [10] \\nused feature selection methods to detect image targets, \\nwhich can achieve real-time detection and a high detection \\nrate. \\nThis paper summarizes the image processing technology, \\ncompares various image technology in detail, and explains \\nthe limitations of each image processing method. In \\naddition, this paper introduces machine learning algorithm \\nin image processing technology, and applies convolution \\nneural network to feature extraction in image processing, so \\nas to effectively improve the accuracy of image \\nsegmentation, image classification and target detection, \\nwhich proves the superiority of image processing \\ntechnology based on machine learning. \\nII. MACHINE LEARNING AND IMAGE PROCESSING \\nA. Image processing \\n(1)Image Enhancement \\nImage enhancement technology adjusts various attributes \\nof the image to make the image clearer, such as adjusting \\nthe brightness, contrast, saturation, and hue of the image to \\nincrease its clarity and reduce noise. The method of image \\nenhancement is to add some information or transform data \\nto the original image by certain means, selectively highlight \\nthe features of interest in the image or suppress some \\nunwanted features in the image, so that the image matches \\nthe visual response characteristics. Sometimes the acquired \\nimage is dark, low contrast and noisy. Among them, image \\nenhancement can be divided into two categories: frequency \\ndomain method and space domain method. The former \\nregards the image as a two-dimensional signal and \\nperforms signal enhancement based on the two-dimensional \\nFourier transform. The representative algorithms in the \\nlatter spatial domain method include local averaging \\nmethod and median filtering method. At this time, the \\nimage needs to be enhanced. Histogram equalization is an \\nimportant image enhancement technology that can be used \\nfor the entire image or the extracted parts of the image. \\nBoth genetic algorithm and particle swarm algorithm have \\nthe limitation of falling into local minimum. There is also a \\ndirect transformation of the image to achieve the effect of \\nimage enhancement, such as: Laplacian transformation of \\nthe image using Laplacian operator, Log transformation \\nand gamma transformation of the image, etc. Table 1 \\nAuthorized licensed use limited to: SRM Institute of Science and Technology. Downloaded on December 11,2023 at 09:12:24 UTC from IEEE Xplore.  Restrictions apply.\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2013; modified using iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'Appligent AppendPDF Pro 5.5', 'creationdate': '2022-02-11T10:30:48-05:00', 'moddate': '2022-02-11T11:27:56-05:00', 'ieee article id': '9712416', 'ieee issue id': '9085929', 'subject': 'IEEE Consumer Electronics Magazine; ;PP;99;10.1109/MCE.2022.3150659', 'ieee publication id': '5962380', 'title': 'Image Processing Technology Based on Machine Learning', 'appligent': 'AppendPDF Pro 5.5 Linux Kernel 2.6 64bit Oct  2 2014 Library 10.1.0', 'source': 'Image_Processing_Technology_Based_on_Machine_Learning.pdf', 'total_pages': 6, 'page': 1, 'page_label': '2'}, page_content='2162-2248 (c) 2021 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.\\nThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/MCE.2022.3150659, IEEE\\nConsumer Electronics Magazine\\nselects several image enhancement algorithms for \\ncomparison. And digital image processing has rapidly \\ndeveloped into an independent subject with strong vitality \\nin more than 40 years. Image enhancement technology has \\ngradually involved all aspects of human life and social \\nproduction, and it plays a role in the fields of aerospace, \\nbiomedicine, industrial production, and public security. \\nTABLE 1 \\nSEVERAL IMAGE ENHANCEMENT ALGORITHMS \\nAuthor work Algorithm \\nY.C. Chang [11] Contrast and brightness \\nenhancement \\nHistogram \\ntransplantation \\nS. Suresh and S. \\nLal [12] \\nContrast and brightness \\nenhancement \\nModified differential \\nevolution \\nIn recent years, the combination of various optimisation \\ntechniques has also been of great interest. One method is \\nthe combination of a socket search (CS) with a particle \\ncluster optimization algorithm. The cuckoo search is a \\nglobal search algorithm based on population. Combining \\nwith the particle cluster algorithm and the genetic \\nalgorithm, has better results than the separate particle \\nalgorithm and the genetic algorithm in the best solution \\napproach[13]. \\nNext, we select several of the most common and simple \\nimage enhancement algorithms for detailed description. \\n1) Image enhancement based on histogram equalization \\nThe main principle of the tool for histogram equalization \\nbased image enhancement algorithm is to redistribute the \\npixel values of the image. Its general application scenario is \\nto increase the local contrast of the image. The image \\napplied by the algorithm needs to have similar contrast \\nbetween the local images of the interested part. For \\nexample, histogram equalization can be used to make the \\ncontrast of the over exposed and underexposed images \\nmore prominent, And the image with obvious difference \\nbetween foreground and background. Among them, the \\nimage enhancement algorithm still has certain defects. \\nSome images have high peaks and the contrast will not be \\nnaturally enhanced after processing; and the grayscale of \\nthe transformed image is reduced, and some details are \\nreduced. \\nThe calculation process of histogram equalization \\nalgorithm is as follows: \\nThe first step, equalization process: histogram \\nequalization ensures that the original size relationship \\nremains unchanged in the process of image pixel mapping, \\nthat is, the brighter area is still brighter, the darker area is \\nstill darker, but the contrast is increased, and the brightness \\ncannot be reversed; the value range of pixel mapping \\nfunction is between 0 and 255. The cumulative distribution \\nfunction is a single growth function, and the range is 0 to 1. \\nThe second step is to realize the cumulative distribution \\nfunction \\nComparing the probability distribution function with the \\ncumulative distribution function, the two-dimensional \\nimage of the former is uneven, and the latter is \\nmonotonically increasing. In the process of histogram \\nequalization, the calculation formula of mapping method is \\nas follows: \\nsk = ∑\\nnj\\nn\\nk\\nj=0     K = 1,2,3, . . L − 1        (1) \\n2) Image enhancement based on Laplacian operator \\nThe image strengthening algorithm based on the Laplace \\noperator uses the Laplace operator for image strengthening. \\nThe major thought is to degrade the image by using the \\nsecond differential of the image. In the image field, the \\ndifferentiation is sharpening, and the integral is blurring. \\nThe use of second-order differentiation to degenerate the \\nimage is the use of neighboring pixels to improve contrast. \\nThere is also a Laplacian function in OpenCV, because \\nOpenCV performs Laplace transform on an image. The \\nimage is a grayscale image, so it is equivalent to extracting \\nmore edge information of the image. The Laplace transform \\nof digital images generally uses a 3×3 convolution kernel to \\nconvolve the image, and then an enhanced image can be \\nobtained. Among them, the main medium for human \\ntransmission of information is language and image. \\nAccording to statistics, visual information accounts for 80% \\nof the various information received by humans, so image \\ninformation is a very important information transmission \\nmedium and method. The convolution kernel is self-defined \\naccording to experimental needs. The convolution kernel \\nused in this article is shown in Figure 1. \\n0 0-1\\n-1\\n0\\n5\\n-1\\n-1\\n0\\n \\nFigure 1.  Laplacian convolution kernel \\n3)Image enhancement based on gamma transformation \\nGamma transform mainly rectifies pictures having high \\nor weak grayscale values to strengthen the comparison and \\nachieve the effect of image correction. The calculation \\nformula is as follows: \\ns = Crγ rϵ[0,1]                (2) \\nWhere C is a constant, γ is the gamma coefficient, and \\nS is the pixel value after transformation. Choose different \\nγ to get different gamma curves as shown in Figure 2. \\n \\nFigure 2.  Gamma curve \\nFrom Figure 2, we can see some rules. γ = 1 is the \\ndividing line. When γ < 1, the small gray value of the \\nimage has a strong expansion effect. The smaller the value, \\nthe stronger the effect. In addition, when the value of γ > 1, \\nthe expansion effect of large gray value of the image will \\nalso be enhanced, and the larger the value, the stronger the \\neffect. In this way, we can change the value of gamma to \\nachieve the purpose of enhancing low gray.  \\n(2)Feature Extraction \\nImage features contain the basic information of the \\nAuthorized licensed use limited to: SRM Institute of Science and Technology. Downloaded on December 11,2023 at 09:12:24 UTC from IEEE Xplore.  Restrictions apply.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2013; modified using iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'Appligent AppendPDF Pro 5.5', 'creationdate': '2022-02-11T10:30:48-05:00', 'moddate': '2022-02-11T11:27:56-05:00', 'ieee article id': '9712416', 'ieee issue id': '9085929', 'subject': 'IEEE Consumer Electronics Magazine; ;PP;99;10.1109/MCE.2022.3150659', 'ieee publication id': '5962380', 'title': 'Image Processing Technology Based on Machine Learning', 'appligent': 'AppendPDF Pro 5.5 Linux Kernel 2.6 64bit Oct  2 2014 Library 10.1.0', 'source': 'Image_Processing_Technology_Based_on_Machine_Learning.pdf', 'total_pages': 6, 'page': 2, 'page_label': '3'}, page_content='2162-2248 (c) 2021 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.\\nThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/MCE.2022.3150659, IEEE\\nConsumer Electronics Magazine\\nimage, including geometric features, shape features, texture \\nfeatures, etc. image features are very important in the \\nprocess of image analysis and processing. According to the \\nprevious research experience, the number of extracted \\nimage features is not the more the better. The more image \\nfeatures, on the contrary, will increase the time of feature \\nextraction in the process of recognition and detection, thus \\nreducing the efficiency of detection. Among them, there are \\nmany factors that affect the clarity of image quality. The \\nuneven outdoor illumination will cause the image gray to \\nbe too concentrated; the image obtained by the camera \\nundergoes digital/analog conversion, and noise pollution \\noccurs during line transmission. The image quality will \\ninevitably decrease. In the lighter case, the image is \\naccompanied by noise and it is difficult to see the details of \\nthe image; the more severe case, the image is blurred, and \\neven the outline of the object is difficult to see clearly. The \\nfeatures of images should have the following properties: \\n1) Scale invariance; \\n2) Rotation invariance; \\n3) It has strong anti noise ability and stable robustness to \\nillumination; \\n4) At the same time, it has lower feature dimension. \\nTable 2 is a comparison of some feature extraction. \\nTABLE 2 \\nFEATURE EXTRACTION ALGORITHM \\nAlgorithm Feature extraction limitation \\nMulti-image saliency \\nanalysis  \\nExtract ROI Unwanted \\nbackground \\ninformation appears \\nUnified capability \\nfeature extraction  \\nRotation and \\nscale-invariant local \\nfeatures \\nDifferent matching \\nresults for different \\ndata \\nDigital surface model Pixel and feature level \\nextraction of urban \\nscenes \\nMulti-feature \\nclassification is \\ndifficult \\nReversible jump \\nMarkov chain Monte \\nCarlo sampler \\nExtract features such \\nas rivers, channels and \\nroads \\nToo sensitive to \\nexperimental settings \\nThese are artificially designed features. With the \\npopularity of deep learning, the most popular feature \\nextraction method is feature extraction based on CNN. \\nNow we will explain the feature extraction of hog and LBP. \\n1)HOG features \\nThe HOG characteristic is a local feature and the HOG \\ncharacteristic is obtained from computing and counting the \\ngrade histogram of the image. The HOG feature has image \\ngeometry and optical invariance characteristics because it \\noperates on a partial image. The procedure of HOG \\nfunction selection is as below: \\nIn the first step, the image is converted into a gray \\nimage, and the conversion formula is as follows: \\nGary = 0.3R + 0.59G + 0.11B          (3) \\nIn the second step, gamma correction is used to \\nnormalize the color information of the image to eliminate \\nthe color interference. The calculation formula is as \\nfollows: \\nI2(x, y) = I1(x, y)Gamma            (4) \\nWhere I1(x, y) is the value before correction, I2(x, y) \\nis the value after correction, and Gamma is the correction \\ncoefficient. \\nThen use the results of formulas (5) and (6) to calculate \\nthe amplitude and phase. The calculation formula is as \\nfollows: \\n𝛼(𝑥, 𝑦) = 𝑡𝑎𝑛−1(\\n𝐺𝑦(𝑥,𝑦)\\n𝐺𝑥(𝑥,𝑦)\\n)            (5) \\nWhere H(x, y) is the value at (x, y), and G(x, y) and \\nα(x, y) are amplitude and phase respectively. \\nIn the fourth step, the image is divided into image \\nblocks, and then the image blocks are divided into cell \\nunits. The shape of cell unit can be set by itself. For \\nexample, the size of image block is divided into 16 × 16, \\nand then each image block is divided into four 8 × 8 cell \\nunits; \\nThe fifth step is to count the gradient histogram of each \\ncell to form the feature descriptor of each cell; suppose that \\nthe histogram is divided into 9 bin from 0 to 360 degrees to \\ncount the gradient information of 8 × 8 pixels to form a \\n9\\n-dimensional feature vector. \\nIn the sixth step, four cells are formed into an image \\nblock, and the hog feature descriptors of all cells in an \\nimage block are put together to get the hog feature \\ndescriptor of the image block. \\n2)LBP features \\nThe LBP feature is a local feature of an image. Its core \\nidea is to use the pixel value of the center pixel of the \\nimage block as the threshold, and then compare the \\nsurrounding pixel values with the threshold. If the value \\nexceeds the limit, it shall be recorded as 1, otherwise \\nrecorded as 0. Classify these 1 and 0 to create a binary \\nnumber to represent the text information of the image. If \\nthe image block size is 3×3, an eight-bit binary number is \\ngenerated. Taking a 3×3 image block as an example, the \\nLBP extraction process is shown in Figure 3. Calculated as \\nfollows: \\n𝐿𝐵𝑃 =∑ 2𝑝 7\\n𝑝=0 𝑓(𝑔𝑝 − 𝑔𝑐)           (6) \\nAmong them, gc  and gp  are the pixel value of the \\ncentral pixel and the pixel value of the p-th domain pixel \\nrespectively. f(x) is a step function, and its expression is as \\nfollows: \\n𝑓(𝑥) {1     𝑥 ≥ 0\\n0     𝑥 < 0                (7) \\n78 65 26\\n100 75 98\\n63 18 83\\n1 0 0\\n1 1\\n0 0 1\\n(10011001)2=(153)10\\n \\nFigure 3.  LBP feature extraction \\n3) SIFT features \\nSift is a scale invariant feature inspection method. To \\nachieve scale invariance, Sift constructs an image scale \\nspace, which is constant to the scaling, rotation and \\nradiation shift of the image. \\nFirstly, the image scale space is generated, that is, the \\noriginal image is sampled according to different \\nfrequencies to obtain multiple zoomed images; then, the \\nlocal extremum points in the scale space are detected, \\nwhich may include edge response points and some points \\nwith low contrast, which need to be excluded to leave the \\nlocal extremum points which can reflect the image features \\nAuthorized licensed use limited to: SRM Institute of Science and Technology. Downloaded on December 11,2023 at 09:12:24 UTC from IEEE Xplore.  Restrictions apply.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2013; modified using iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'Appligent AppendPDF Pro 5.5', 'creationdate': '2022-02-11T10:30:48-05:00', 'moddate': '2022-02-11T11:27:56-05:00', 'ieee article id': '9712416', 'ieee issue id': '9085929', 'subject': 'IEEE Consumer Electronics Magazine; ;PP;99;10.1109/MCE.2022.3150659', 'ieee publication id': '5962380', 'title': 'Image Processing Technology Based on Machine Learning', 'appligent': 'AppendPDF Pro 5.5 Linux Kernel 2.6 64bit Oct  2 2014 Library 10.1.0', 'source': 'Image_Processing_Technology_Based_on_Machine_Learning.pdf', 'total_pages': 6, 'page': 3, 'page_label': '4'}, page_content='2162-2248 (c) 2021 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.\\nThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/MCE.2022.3150659, IEEE\\nConsumer Electronics Magazine\\nmore accurately, The histogram gradient direction of the \\nregion centered on the extreme point is counted, and the \\nmaximum direction is taken as the main direction to \\ngenerate the feature descriptor. The calculation method of \\nfeature descriptor is to take 16×16 window around the \\nfeature and use Gaussian weighting to draw histogram of \\ngradient direction in 8 directions on 4×4 image block, and \\ncount the accumulated value of each gradient direction to \\nform a seed point. The gradient histogram of each seed \\npoint contains 8 values, a total of 128 values, which are \\ncombined into a 128 dimensional SIFT feature vector. \\nThe matching of feature points is calculated by nearest \\nneighbor algorithm, that is, the Euclidean distance between \\nfeature description vectors is calculated, and the point with \\nthe smallest distance is selected for matching. \\n(3) Image segmentation \\nFragmentation is the classification of image cells into \\ndifferent categories, so that there are some relevant parts in \\neach category. This is very important when you are trying \\nto identify some important areas in an image, such as forest \\ncover, pedestrians and vehicles. With the introduction of \\npost-European, researchers extend the combination of these \\nalgorithms to the segmentation field. \\nTable 3 shows the comparative analysis results of some \\nimage segmentation. \\nTABLE 3 \\nCOMPARISON OF IMAGE SEGMENTATION ALGORITHMS \\nImage segmentation Advantage \\nCuckoo search, McCulloch \\nmethod \\nHigh computational efficiency and \\ngood convergence \\nMarkov Random Field Algorithm  Use fewer features to achieve \\nhigher accuracy \\nDeep Convolutional Neural \\nNetwork \\nEfficient boundary extraction \\nimproves classification \\nZhenghang Firefly Algorithm Multi-level subdivision and less \\ncalculation time \\nThe methods used include quantification, clustering and \\nthe possibility of finding the minimum number of clusters. \\nIn DCCN algorithm, limit detection is first added to a \\nfragmented encoder to create a new model. It\\'s a \\ncombination of a collective network and a coder, but the \\nmain disadvantage of this model is that it\\'s a very large \\nmodel, which merits attention for researchers. using this \\nmodel. And the export limit is very vague. \\n(4) Image target detection \\nThe target detection method could be classified into two \\nsections: target placement and target identification. The \\nposition of the target and the target category are precisely \\nin the known image. Under normal circumstances, the \\ntarget in the image is uncertain, length, width, height, \\nangle, etc. is random or there is a situation where the target \\nis not uniform, but includes multiple categories, which \\nbring recognition and the target position of the day. A \\ncertain degree of complexity. \\n(5) Image filtering \\nFiltering is a common method to eliminate interferen ce \\nin image preprocessing. It can not only suppress the image \\nnoise, but also ensure that the edge information of the \\ntarget in the image is not destroyed. There are many \\nmethods for image filtering, including Gaussian filtering, \\nmean filtering and other linear filtering, as well as median \\nfiltering and bilateral filtering in nonlinear filtering. \\n1) Gaussian filtering \\nGaussian filtering is mainly used to eliminate Gaussian \\nnoise. Its filtering process is to weighted average the gray \\nvalue of the image, that is, a two-dimensional scale factor \\nof the Gaussian kernel convolutes with the pixels in the \\nimage to remove the noise. \\n2) Median filtering \\nMedian filter is a classical nonlinear filtering method, \\nwhich is very effective to eliminate salt and pepper noise, \\nand has a special role in the phase analysis of optical \\nmeasurement fringe image. The implementation process is \\nas follows: the first step is to take the odd number of \\nsampling points from a given sampling window in the \\nimage. The second step is to assign the middle data to the \\ncurrent pixel according to the sorted values. \\n3) Edge filtering \\nThis method combines the compromise of geometric \\nspace proximity and pixel difference. Based on Gaussian \\nfiltering, bilateral filtering has an extra Gaussian variance.  \\nTherefore, pixels far away from the edge will not have \\nmuch impact on the edge pixels. \\nB. Machine Learning \\n(1) Machine learning \\nWhat is machine learning? Machine learning is a \\nmultidisciplinary cross-specialty , covering knowledge of \\nprobability theory , statistics, approximate theory and \\ncomplex algorithm knowledge. Use computer as a tool and \\ndevote to real and real-time simulation of human learning \\nmethods, and divide existing content into knowledge \\nstructure to effectively improve learning efficiency . W e \\nknow that human beings will have a variety of experiences \\nin the process of growth and life, and we will regularly \\nsummarize these past history or experience, and draw \\ncertain \"rules of law\". Sometimes we will label the results \\nof these \"rule rules\", such as successful, failed, correct, \\nwrong and so on. In this way , when we are faced with some \\nnew things that need to be judged and speculated, we will \\nnaturally search for and use some of the \"rules\" we \\nsummarize to guide our future life and work. Machine \\nlearning simulates the \"learning\" mode of human beings. It \\nestablishes a set of \"models\" by training the existing data, \\nso as to predict the new input data. Among them, the \\ncommon algorithms of machine learning include decision \\ntree algorithm, naive Bayes algorithm, support vector \\nmachine algorithm, random forest algorithm and artificial \\nneural network algorithm. And machine learning has a wide \\nrange of applications. Whether in the military or civilian \\nfields, there are opportunities for machine learning \\nalgorithms, including data analysis and mining, pattern \\nrecognition, and bioinformatics. \\n(2) Convolution neural network \\nThe research on convolutional neural networks can be \\ntraced back to the neocognitron model proposed by \\nJapanese scholar Kunihiko Fukushima. Convolutional \\nneural network is a widely used machine learning model, \\nwhich is mainly used for classification and prediction. The \\nstructure of convolutional neural network includes input \\nlayer, hidden layer and output layer. Because of its \\nmulti-layer network structure, it can be used to approximate \\nsome more complex functions. The traditional image \\nprocessing technology is relatively seriously affected by the \\nenvironment. The convolution neural network has strong \\nrobustness, which greatly improves the recognition \\nAuthorized licensed use limited to: SRM Institute of Science and Technology. Downloaded on December 11,2023 at 09:12:24 UTC from IEEE Xplore.  Restrictions apply.'),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2013; modified using iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'Appligent AppendPDF Pro 5.5', 'creationdate': '2022-02-11T10:30:48-05:00', 'moddate': '2022-02-11T11:27:56-05:00', 'ieee article id': '9712416', 'ieee issue id': '9085929', 'subject': 'IEEE Consumer Electronics Magazine; ;PP;99;10.1109/MCE.2022.3150659', 'ieee publication id': '5962380', 'title': 'Image Processing Technology Based on Machine Learning', 'appligent': 'AppendPDF Pro 5.5 Linux Kernel 2.6 64bit Oct  2 2014 Library 10.1.0', 'source': 'Image_Processing_Technology_Based_on_Machine_Learning.pdf', 'total_pages': 6, 'page': 4, 'page_label': '5'}, page_content=\"2162-2248 (c) 2021 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.\\nThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/MCE.2022.3150659, IEEE\\nConsumer Electronics Magazine\\naccuracy. The connections between convolutional layers in \\na convolutional neural network are called sparse \\nconnections. That is, compared with the full connection in \\nthe feedforward neural network, the neurons in the \\nconvolutional layer are only connected to a part of its \\nadjacent layer, not all neurons. As a representative \\nalgorithm of deep learning, convolutional neural network \\nhas the ability to characterize learning, that is, it can extract \\nhigh-order features from input information. \\n1) Characteristics and structure of convolution neural \\nnetwork \\nIts unique characteristics are determined by its structure. \\nIts main characteristic is that the weights of the connected \\ntwo layers of neurons are not completely connected. And in \\nmany neural network layers, the weights that connect the \\ntwo layers of neural networks are not completely \\nconnected, and the connection weights of neurons in the \\nsame layer under the same filter are the same. These \\nfeatures reduce the number of weights and complexity of \\nthe network model. \\n2) The characteristics of convolution neural network \\nConvolutional neural networks are built on top of \\ntraditional neural networks by increasing the depth of each \\nlayer and signal processing. Its basic signal conduction is \\nthe same as the traditional neural network, which processes \\nthe leading signal through the neuron structure. The main \\nnetwork layer can be divided into two types: convolution \\nlayer and pooling layer. \\nEach layer of CNN can have some activation function to \\naccept the product sum of input and weight, except for \\ninput layer. With the help of activation function, CNN \\nselects the features extracted from the network by nonlinear \\nmapping to avoid the problem of insufficient expression \\nability of linear operation. \\n(3) Feature extraction based on CNN \\nIn this paper, CNN is applied to feature extraction of \\nimage processing. Therefore, the feature extracted by CNN \\nhas translation invariability. Using CNN to extract features \\nis divided into the following steps: \\n1)Convolution layer: Use the convolution kernel to \\nconvolve the input image to obtain the result after \\nconvolution, and then pass it to the excitation layer. The \\nconvolution operation process is shown in Figure 4. \\n1 11\\n0\\n0\\n1\\n0\\n1\\n1\\n1 10\\n0\\n1\\n1\\n0\\n0\\n101\\n0 0\\n0 10\\n0 1 1\\n0 0\\n1\\n1\\n0\\n1\\n4 43\\n2\\n2\\n4\\n3\\n3\\n4\\n \\n \\nFigure 4.  Convolution operation process \\n2)Excitation layer:Use the activation function to perform \\na nonlinear mapping on the output of the convolution layer. \\nThe activation function is shown below. \\nf(x)= max (0, x)              (8) \\n3)Pooling layer: Reduce the dimensionality of the output \\nof the excitation. Since the input passes through the \\nconvolutional layer, if the convolution kernel is relatively \\nsmall,while maintaining the image depth while reducing the \\ndimensionality, the pooling layer generally uses maximum \\npooling, and the calculation process is shown in Figure 5. \\n1 21\\n5\\n3\\n6\\n2\\n7\\n1\\n41 32\\n4\\n8\\n0\\nY\\nX Maxpool with 2x2 \\nfilters and stride 2 6 8\\n3 4\\n \\nFigure 5.  Maximum pooling process \\nThe pooling process is also moved on the input graph \\nwith a window. The difference between the three pooling \\nmethods lies in the value calculation in the window. The \\nmaximum pooling is the maximum value; the average \\npooling is the average value of the sub sampling fast \\nelements; and the random pooling is the random value \\naccording to its probability. Pooling is also a kind of \\nspecial convolution kernel, but the difference is that \\npooling acts on non coincident regions in the image. \\n4) Fully connected layer: Re-fitting features to reduce the \\nloss of feature information, turning the feature map output \\nby the pooling layer into a one-dimensional feature vector, \\nthis one-dimensional feature vector is the feature that can \\nbe used for subsequent processing. \\nIII. PERFORMANCE EVALUATION METHOD AND ANALYSIS \\nA. Performance Evaluation Method \\nWe know that quality evaluation is very subjective. \\nMany parameters must be used for quality evaluation. \\nMoreover, there is opposition to it being exceptional. \\nQuality evaluation should be compared with existing \\ntechnologies to highlight the superiority of the algorithm in \\nthis Article. The calculation parameters selected in this \\ndocument include FSIM, SSIM, the Accuracy and \\nWithdrawal Rate. \\n(1) FSIM \\nThe FSIM refers to the similarity of characteristics \\nbetween the input image and the final image, which is \\ncalculated as follows: \\n𝐹𝑆𝐼𝑀 =\\n∑ 𝑆𝐿(𝑥)𝑃𝐶𝑚(𝑥)𝑥𝜖𝑋\\n∑ 𝑃𝐶𝑚(𝑥)𝑥𝜖𝑋\\n            (9) \\n(2) SSIM \\nThe SSIM entry specifies the format of the sequence \\nbetween the last image and the sequence. The calculation \\nformula is as follows: \\nSSIM =\\n2μxμy+C1\\nμx2+μy2+C1\\n        (10) \\n(3) Accuracy \\nExactly, it's an attempt to underestimate the overall \\nimpact of his work. The calculation formula is as follows: \\n𝑝𝑟𝑒𝑐𝑖𝑠𝑖𝑜𝑛 =\\n∑ 𝐺𝑇𝑖𝐵𝑊𝑖𝑁\\n𝑖=1\\n∑ 𝐵𝑊𝑖𝑁\\n𝑖=1\\n             (11) \\nWhere BWi is the binary image of the i-th pixel, GTi=\\n1 means that the i-th pixel belongs to the region of interest, \\nand GTi= 0 means that the i-th pixel e does not exist in \\nthe ROI. \\n(4) Recall rate \\nThe Recall rate is the reason for the correct comments \\ncorrectly provided for in the overall comments. The \\ncalculation type shall be as follows: \\nrecall =\\n∑ GTiBWiN\\ni=1\\n∑ GTiN\\ni=1\\n                (12) \\nThis metric includes both false positives and false \\nAuthorized licensed use limited to: SRM Institute of Science and Technology. Downloaded on December 11,2023 at 09:12:24 UTC from IEEE Xplore.  Restrictions apply.\"),\n",
       " Document(metadata={'producer': 'Microsoft® Word 2013; modified using iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'Appligent AppendPDF Pro 5.5', 'creationdate': '2022-02-11T10:30:48-05:00', 'moddate': '2022-02-11T11:27:56-05:00', 'ieee article id': '9712416', 'ieee issue id': '9085929', 'subject': 'IEEE Consumer Electronics Magazine; ;PP;99;10.1109/MCE.2022.3150659', 'ieee publication id': '5962380', 'title': 'Image Processing Technology Based on Machine Learning', 'appligent': 'AppendPDF Pro 5.5 Linux Kernel 2.6 64bit Oct  2 2014 Library 10.1.0', 'source': 'Image_Processing_Technology_Based_on_Machine_Learning.pdf', 'total_pages': 6, 'page': 5, 'page_label': '6'}, page_content=\"2162-2248 (c) 2021 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See http://www.ieee.org/publications_standards/publications/rights/index.html for more information.\\nThis article has been accepted for publication in a future issue of this journal, but has not been fully edited. Content may change prior to final publication. Citation information: DOI 10.1109/MCE.2022.3150659, IEEE\\nConsumer Electronics Magazine\\nnegatives, taking false negatives into account.  \\nB. Performance Evaluation Analysis \\nROC curve, also known as receiver operating \\ncharacteristic curve, is also a performance evaluation \\nstandard. This curve is the effect under all possible \\nclassification thresholds. This curve is used to draw TP and \\nFP when different classification thresholds are used. \\nLowering the classification threshold will result in more \\nsamples being classified as positive, thereby increasing the \\nnumber of false positive and true examples. \\nThe ROC curve is shown in Figure 6. Figure 6(a) in the \\nfigure shows that under ideal conditions. \\n#\\nTNTP\\nFP FN\\nd\\n1\\n0.8\\n1\\n0 0.1\\nrandom chance\\nequal error \\nrate\\nfalse positive rate\\ntrue positive rate\\n \\n(a) (b) \\nFigure 6. ROC curve \\nIn this paper, the image segmentation, image \\nclassification and target detection algorithms based on deep \\nlearning are implemented on the public data and the above. \\nThe performance of each algorithm is quantitatively \\nanalyzed, and the performance simulation results are given. \\nImage segmentation uses the VOC2007 data set, target \\ndetection uses the imagenet data set, and image \\nclassification uses the CIFAR100 data set. \\nFrom Figures 7, 8 and 9, we can see that, and Figure 9, \\nthat the image segmentation, classification and target \\ndetection based on deep learning algorithm can achieve \\nhigh accuracy. Among them, the image segmentation \\naccuracy reaches 0.984, the image classification accuracy is \\n0.987, and the target detection accuracy rate is 0.986. \\nIV. CONCLUSION \\nWith the development of science and technology, \\nmachine learning technology has rapidly returned to \\npeople's vision. Machine learning technology provides \\nconvenience for many aspects of modern society. The \\nautomatic target tracking research in the field of image \\nprocessing, go game and unmanned driving are all involved \\nin the important technical field of machine learning. For \\nthis reason, the accuracy of machine learning image \\nprocessing is improved based on the image processing \\naccuracy of machine learning. \\nIn this paper, the current popular image processing \\ntechnology is summarized, and various image technology \\nare compared in detail, and the limitations of each image \\nprocessing method are explained. Then machine learning is \\nintroduced into image processing technology. In the feature \\nextraction of image processing, convolution neural network \\nis used to extract image features. The voc2007 data set, \\nImagenet data set and cifar100 data set are selected for \\nimage segmentation, target detection and image \\nclassification simulation tests, and their performance is \\nevaluated by ROC curve. \\nThe results show that the image processing technology \\nbased on machine learning can effectively improve the \\naccuracy of image segmentation, classification and target \\ndetection. Artificial intelligence will continue to be a hot \\ntopic in the future decades, and as the most important \\nresearch field of artificial intelligence, machine learning, \\nevolutionary algorithm will also be greatly brilliant. We \\nbelieve that the application of machine learning in image \\nprocessing technology is more and more extensive, and the \\nresearch results of this paper will also provide some \\nreference value for this. \\nREFERENCES \\n[1] Zhang Hui, Wang Kunfeng, Wang Feiyue. Application and progress \\nof deep learning in target detection . Acta Automatica Sinica, 2017, 43(8): \\n1289-1305.  \\n[2] Z. Zhu, H. Yin, Y. Chai, Y. Li and G. Qi. A novel multi-modality \\nimage fusion method based on image decomposition and sparse \\nrepresentation. Information Sciences, 2017, 2(432):  516- 529. \\n[3] L. Mauryaa, P. K. Mahapatraa and A. Kumara. A social spider \\noptimized image fusion approach for contrast enhancement and brightness \\npreservation. Applied Soft Comp, 2016, 1(52): 575- 592. \\n[4] J. Zou, W. Li, C. Chen and Q. Du. Scene classification using local \\nand global features with collaborative representation fusion. Information \\nSciences, 2016, 10(348):209-226. \\n[5] K. Li, C. Zou, S. Bu, Y. Liang, J.Zhang and M. Gong . Multimodal \\nfeature fusion for geographic image annotation. Pattern Recognition, \\n2017,1(73): 1-14. \\n[6] J. A. Montesinos, M. Martínez-Durb_an, J. del Sagrado, I.M. \\ndel_Aguila, F.J. Batlles. The application of Bayesian network classifiers to \\ncloud classification in satellite images. Renewable Energy, 2016, 10(97): \\n155-161. \\n[7] A. Singh and K. K. Singh. Satellite image classification using \\nGenetic Algorithm trained radial basis function neural network, \\napplication to the detection of flooded areas. J. Vis. Commun. Image R, \\n2016, 2(42): 173-182. \\n[8] L. Maa, M. Li, X. Mac, L. Cheng, P. Dua and Y. Liu. A review of \\nsupervised object-based land-cover image classification. ISPRS J. \\nPhotogramm. and Remote Sens, 2017, 10(130): 277- 293. \\n[9] Q. Liu, R. Hang, H. Song, and Z. Li. Learning Multiscale Deep \\nFeatures for High- Resolution Satellite Image Scene Classification. IEEE \\nTrans. Geoscience and Remote Sensing, 2017, 1(56): 117- 126. \\n[10] D. Meraa, V. Bolon-Canedo, J.M. Cotosa, A. Alonso-Betanzos, On \\nthe use of feature selection to improve the detection of sea oil spills in \\nSAR images. Computers and Geosciences, 2016, 1(100): 166- 178. \\n[11] Y. C. Chang. A flexible contrast enhancement method with visual \\neffects and brightness preservation: Histogram planting . Computers and \\nElectrical Engg. 2017, 10(12):1-12.  \\n[12] S. Suresh and S. Lal. Modified differential evolution algorithm for \\ncontrast and brightness enhancement of satellite images . Applied Soft \\nComputing, 2017, 2(61): 622 –641. \\n[13] H. Singh, A. Kumar, L.K. Balyan and G.K. Singh. A novel \\noptimally weighted framework of piecewise gamma corrected fractional \\norder masking for satellite image enhancement . Computers and Electrical \\nEngg, 2017, 7(10): 1-7. \\n \\nQiong Qiao was born in Jining, \\nShandong, China, in 1989. She received \\nthe Master degree from Communication \\nUniversity of China, Beijing, China. \\nNow, she studies in -School of \\nInformation and Communication \\nEngineering, Communication University \\nof China. Her research interests include picture processing, \\nartificial intelligence and audio signal processing. \\nAuthorized licensed use limited to: SRM Institute of Science and Technology. Downloaded on December 11,2023 at 09:12:24 UTC from IEEE Xplore.  Restrictions apply.\")]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33efd810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of documents: 50\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000)\n",
    "docs = text_splitter.split_documents(data) \n",
    "print(\"Total number of documents:\", len(texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2945b7c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'Microsoft® Word 2013; modified using iText® 7.1.1 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'Appligent AppendPDF Pro 5.5', 'creationdate': '2022-02-11T10:30:48-05:00', 'moddate': '2022-02-11T11:27:56-05:00', 'ieee article id': '9712416', 'ieee issue id': '9085929', 'subject': 'IEEE Consumer Electronics Magazine; ;PP;99;10.1109/MCE.2022.3150659', 'ieee publication id': '5962380', 'title': 'Image Processing Technology Based on Machine Learning', 'appligent': 'AppendPDF Pro 5.5 Linux Kernel 2.6 64bit Oct  2 2014 Library 10.1.0', 'source': 'Image_Processing_Technology_Based_on_Machine_Learning.pdf', 'total_pages': 6, 'page': 0, 'page_label': '1'}, page_content='proposed a social spider optimized image fusion method, \\nwhich can increase contrast while maintaining brightness \\nwhile fusing images.K. Li et al. [5] used multi-peak feature \\nfusion for map labeling, which can effectively improve \\nlabeling accuracy. Montesinos et al. [6] use Bayesian \\nnetwork to classify images, and the classification accuracy \\ncan be more than 90%. Singh et al. [7] used genetic \\nalgorithm to train genetic function network and then used \\nthe trained model for satellite video categorization, which \\nsolved the problem of inaccurate satellite image \\ncategorization. Maa et al. [8] analyzed an object-based \\nsupervised land cover image classification algorithm. Liu et \\nal. [9] used polyscale depth functions to classify scenes \\nfrom satellite images at high resolution, and the simulation \\naccuracy was significantly improved. D. Meraa et al. [10] \\nused feature selection methods to detect image targets, \\nwhich can achieve real-time detection and a high detection \\nrate.')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "322af88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector: [0.0216510072350502, -0.05326151102781296, -0.01706888899207115, -0.010003247298300266, 0.0028219434898346663, 0.02102307230234146, 0.005405785050243139, -0.011608060449361801, -0.010245861485600471, 0.029342474415898323, 0.027084819972515106, 0.04429858922958374, -0.012020562775433064, -0.01116825733333826, 0.041813015937805176, -0.004172212444245815, 0.03661104291677475, 0.025845151394605637, -0.02883484959602356, -0.02272123284637928, 0.01161108911037445, 0.015260900370776653, -0.028955131769180298, -0.016405928879976273, -0.01337172370404005, -0.008039526641368866, 0.002896621823310852, -0.09910140931606293, -0.047610677778720856, 0.04190785065293312, -0.08954324573278427, 0.02879638597369194, -0.048032958060503006, 0.02850363776087761, 0.02164633199572563, -0.06963147968053818, -0.014206469990313053, -0.016830584034323692, -0.04087647423148155, 0.012827912345528603, -0.020872924476861954, -0.0061292871832847595, -0.04103962332010269, -0.02347959205508232, 0.04610927775502205, -0.04913103207945824, 0.01806454546749592, 0.04892074689269066, 0.020920149981975555, -0.0479244589805603, -0.016364358365535736, 0.03130882978439331, 0.017508046701550484, -0.023712007328867912, -0.006624508649110794, 0.0010549506405368447, 0.014109386131167412, 0.0235387422144413, -0.02247045561671257, -0.008244744502007961, 0.012910237535834312, 0.014237548224627972, -0.034295160323381424, 0.05699284002184868, 0.0025056723970919847, -0.060770291835069656, -0.037837374955415726, 0.025222470983862877, 0.07875017076730728, -0.06673073768615723, 0.05446133017539978, -0.032532062381505966, -0.012157674878835678, -0.04791085794568062, -0.07174981385469437, -0.06620528548955917, 0.004568126518279314, 0.05392373725771904, 0.006038174033164978, -0.004045366775244474, -0.010487714782357216, -0.05806240439414978, -0.028118662536144257, -0.04191378131508827, -0.054873980581760406, 0.018102284520864487, -0.05043857544660568, -0.03289331868290901, -0.029004663228988647, 0.06363371759653091, -0.029077215120196342, -0.039507802575826645, 0.02564193867146969, -0.07248461246490479, 0.00020231860980857164, 0.03495005890727043, 0.0199844129383564, -0.02075851336121559, 0.019803760573267937, -0.037802644073963165, -0.001379487686790526, -0.01591002568602562, -0.001571730594150722, 0.013013826683163643, 0.030745916068553925, 0.03349385783076286, -0.027310147881507874, 0.06038303300738335, -0.02228483185172081, 0.0635368600487709, -0.02773197926580906, 0.000626104767434299, -0.017881231382489204, -0.002109429333359003, -0.006351441610604525, -0.023950673639774323, 0.018968330696225166, 0.04450773820281029, 0.03771255537867546, 0.028965523466467857, -0.005595615599304438, 0.005759084597229958, 0.08652689307928085, 0.03041071631014347, 0.02625575102865696, 0.03485295921564102, 0.040639154613018036, 0.006315188016742468, 0.02428237348794937, 0.040236763656139374, 0.014627471566200256, -0.02700035832822323, 0.03451182693243027, 0.030315106734633446, 0.06117859482765198, 0.009126875549554825, 0.059369105845689774, 0.03146490454673767, 0.0720551460981369, -0.011223847046494484, -0.014675621874630451, 0.002966864500194788, -0.025662224739789963, 0.03858598694205284, -0.02155362069606781, -0.007239309139549732, 0.004210725426673889, 0.002663657069206238, 0.021142609417438507, -0.008288294076919556, -0.006630131974816322, -0.01634098030626774, -0.037847861647605896, 0.029111377894878387, 0.06188208982348442, 0.040141407400369644, 0.003798461752012372, 0.03210744634270668, -0.007541802246123552, -0.02090827189385891, 0.05074101686477661, 0.013776995241641998, -0.005867961328476667, 0.007779087871313095, -0.03589389845728874, -0.016830921173095703, 0.033644769340753555, -0.01749752275645733, 0.012955506332218647, 0.0005591322551481426, 0.044261422008275986, 0.03665325790643692, -0.00298385345377028, -0.07307019084692001, -0.012321515008807182, -0.054948896169662476, -0.0016582764219492674, -0.008628449402749538, -0.024981463328003883, -0.015993956476449966, -0.05437000095844269, -0.06557054817676544, -0.02847139909863472, 0.01990198716521263, 0.03206633776426315, 0.029381487518548965, 0.053807035088539124, -0.028615090996026993, -0.06232443079352379, -0.020790163427591324, 0.013056441210210323, 0.0016177056822925806, -0.03696379438042641, -0.007447964046150446, -0.017172016203403473, 0.06619720906019211, 0.00717694079503417, -0.022455139085650444, 0.019821789115667343, -0.015041738748550415, -0.009559721685945988, 0.11032111942768097, 0.027452988550066948, -0.014536593109369278, 0.008070647716522217, -0.04776708036661148, 0.025380775332450867, -0.02872181124985218, -0.002235634718090296, 0.0585823617875576, -0.09508633613586426, 0.017482688650488853, 0.0009556033182889223, 0.031232481822371483, 0.061751581728458405, 0.03821283206343651, -5.238591256784275e-05, 0.05436553806066513, -0.006993193179368973, -0.0147622125223279, 0.004368732683360577, -0.0037544602528214455, -0.012848702259361744, 0.04238736629486084, 0.023768628016114235, 0.05310846120119095, -0.011838683858513832, 0.02712935023009777, 0.02280057966709137, -0.10372554510831833, -0.0001465238310629502, 0.06340926885604858, 0.03547583147883415, 0.005845553707331419, 0.03630281239748001, 0.019911430776119232, 0.009470573626458645, 0.01592637598514557, -0.0016124607063829899, 0.037683404982089996, -0.04495183378458023, 0.02364487014710903, 0.024389076977968216, -0.003637549001723528, -0.02755185216665268, -0.043999310582876205, -0.018836073577404022, 0.017737427726387978, -0.019053490832448006, 0.031357694417238235, -0.03757137805223465, -0.03495785593986511, 0.054629601538181305, 0.040519263595342636, -0.04288305714726448, 0.03261547535657883, -0.07605751603841782, -0.011183549650013447, 0.01906701549887657, -0.011709875427186489, 0.02414812706410885, -0.004646431654691696, 0.03549028933048248, 0.025096451863646507, -0.040872715413570404, 0.037135858088731766, 0.03438253328204155, -0.050580043345689774, 0.009928705170750618, -0.008602103218436241, 0.017477575689554214, -0.08520418405532837, 0.08180571347475052, -0.003036104841157794, -0.04847871512174606, 0.0387093648314476, -0.011893099173903465, 0.016360722482204437, 0.028898777440190315, -0.025095636025071144, -0.0049682133831083775, 0.049611229449510574, 0.0411800742149353, -0.025753013789653778, -0.07210642099380493, -0.009429866448044777, -0.03973574563860893, 0.0012304272968322039, 0.06071682646870613, -0.07082436233758926, -0.07640763372182846, -0.00547588849440217, 0.006972025148570538, -0.027130229398608208, -0.005203084088861942, -0.0006914595142006874, -0.03908761963248253, 0.047351568937301636, -0.00033719470957294106, -0.019580155611038208, 0.0034205138217657804, -0.05079108104109764, -0.011196507140994072, -0.05828547850251198, -0.026345986872911453, 0.015952853485941887, 0.00838309433311224, -0.04510760307312012, -8.674615673953667e-05, -0.011715690605342388, 0.003988095559179783, -0.05909958481788635, -0.046511270105838776, 0.018373388797044754, 0.04263721778988838, 0.055625393986701965, -0.01062696147710085, -0.01773941144347191, -0.017933331429958344, 0.04632226377725601, 0.0067144776694476604, 0.06775274127721786, 0.028221584856510162, -0.0020409701392054558, 0.008308894000947475, -0.001942240633070469, -0.047793641686439514, 0.06033583730459213, -0.0021162680350244045, 0.01581409201025963, -0.011979861184954643, -0.022247200831770897, 0.007460178807377815, 0.0409461073577404, 0.0036390158347785473, 0.020027978345751762, -0.06398037821054459, -0.02957804501056671, -0.011073026806116104, 0.030692990869283676, 0.007227123249322176, 0.029316026717424393, -0.04274779185652733, -0.02441420778632164, 0.02241899073123932, -0.007668421603739262, 0.014035386964678764, 0.002701778430491686, 0.07653030753135681, -0.0069343456998467445, 0.013679834082722664, 0.05773906782269478, -0.04218214005231857, -0.031705427914857864, 0.008831752464175224, -0.022295057773590088, 0.07087045162916183, -0.027651194483041763, 0.07314875721931458, -0.04902615770697594, -0.07061769813299179, 0.05861210078001022, 0.02955244667828083, -0.005913369357585907, 0.016371743753552437, 0.02746567502617836, 0.01781683787703514, 0.03525375574827194, -0.043320875614881516, 0.015097960829734802, 0.02082923613488674, -0.09116312861442566, 0.01773865707218647, 0.028805864974856377, -0.01603485643863678, -0.05752279981970787, -0.04025113582611084, -0.03918704763054848, 0.012428393587470055, 0.004874950274825096, -0.05510769411921501, -0.01933848112821579, 0.031554896384477615, 0.07958099246025085, -0.0022151265293359756, -0.01856713928282261, 0.021296745166182518, 0.06289030611515045, 0.009573104791343212, 0.03397538140416145, 0.01428967248648405, 0.015048102475702763, 0.10864603519439697, 0.05610563978552818, -0.014843584038317204, -0.022370826452970505, -0.024244241416454315, -0.03246801346540451, 0.032854337245225906, -0.021160617470741272, 0.00463848328217864, -0.029403073713183403, -0.02698102965950966, -0.006966886576265097, -0.06390220671892166, -0.04743213206529617, 0.0017867141868919134, -0.03208180144429207, -0.014784968458116055, 0.012613439001142979, 0.0009056403068825603, 0.05075263977050781, 0.039039723575115204, -0.028898432850837708, -0.07917794585227966, -0.026366649195551872, 0.06496936082839966, -0.03213462978601456, -0.0013217802625149488, -0.006842874456197023, 0.036318715661764145, -0.004049805924296379, 0.015103902667760849, -0.020617766305804253, -0.027435844764113426, -0.037434324622154236, -0.01955568417906761, -0.04393718019127846, 0.004994750022888184, 0.03820565715432167, 0.03260757774114609, 0.013415687717497349, 0.0134592829272151, -0.0007200233521871269, 0.005906505975872278, -0.059986408799886703, 0.022480297833681107, -0.006907701957970858, -0.038098156452178955, 0.005040168296545744, 0.014383940026164055, 0.018109649419784546, 0.0685574933886528, -0.00967130996286869, -0.08237059414386749, -0.01680113561451435, -0.028989538550376892, -0.05176114663481712, 0.018073176965117455, -0.10275080054998398, 0.031856756657361984, -0.09888267517089844, -0.01752540096640587, -0.04415516555309296, 0.0011149464407935739, -0.05979454517364502, -0.026385994628071785, 0.04011031240224838, -0.023762671276926994, 0.006690413691103458, 0.002552882069721818, -0.048711393028497696, 0.0011376988841220737, -0.05208322033286095, 0.04623698815703392, -0.039661917835474014, 0.02220749855041504, -0.012208671309053898, 0.04626937210559845, 0.022381572052836418, -0.03152379393577576, -0.02972133457660675, 0.013679483905434608, 0.009491006843745708, 0.0031781927682459354, 0.015054784715175629, -0.08748992532491684, 0.01689012534916401, -0.03123650886118412, -0.08185627311468124, -0.0021381813567131758, -0.05285274237394333, 0.0587737001478672, 0.020092396065592766, -0.0027156344149261713, -0.02888481505215168, 0.020134538412094116, -0.008484345860779285, 0.013933944515883923, 0.07272589951753616, -0.04924096167087555, 0.030225522816181183, -0.004885381553322077, -0.010086138732731342, -0.025864167138934135, 0.011337431147694588, -0.01993415877223015, 0.021187637001276016, 0.01848270744085312, 0.045787449926137924, 0.01570986956357956, 0.008299330249428749, -0.009128750301897526, 0.007735125720500946, 0.05948607623577118, -0.02209514193236828, 0.002804265823215246, 0.00848373956978321, -0.016176313161849976, 0.03586405888199806, 0.00948755070567131, -0.002797247376292944, 0.005017855204641819, 0.015297221951186657, 0.009286576882004738, 0.04024096578359604, -0.014476911164820194, 0.01179962232708931, 0.032457154244184494, -0.031068135052919388, 0.07167885452508926, -0.01124641951173544, -0.09562167525291443, -0.0210402924567461, 0.015385938808321953, -0.03147165849804878, 0.023281008005142212, 0.04564347863197327, -0.03659427538514137, 0.0218533705919981, -0.002290113130584359, 0.06643347442150116, -0.08673988282680511, 0.003723667934536934, -0.023977693170309067, -0.03782728686928749, -0.012951546348631382, 0.034534480422735214, 0.03702586144208908, 0.016485556960105896, 0.0007503287633880973, -0.029853016138076782, 0.03153350204229355, 0.005860986653715372, 0.02438223734498024, 0.019050084054470062, 0.013669419102370739, -0.12890154123306274, 0.05069988593459129, 0.009370751678943634, 0.003719320287927985, -0.03318127989768982, 0.024353021755814552, -0.05111932009458542, 0.022156061604619026, -0.02038378268480301, -0.013205511495471, 0.011552280746400356, -0.036419086158275604, -0.004770409781485796, -0.021380795165896416, -0.02508721314370632, 0.010730897076427937, -0.03974277898669243, 0.08443151414394379, 0.025688346475362778, -0.06632968038320541, -0.017698273062705994, 0.05395990610122681, -0.02218618430197239, -0.012912055477499962, 0.00025199499214068055, 0.0118872644379735, 0.004275457002222538, 0.03974471241235733, -0.024790605530142784, -0.03305502235889435, 0.014422588981688023, -0.020825220271945, -0.023301666602492332, 0.03767373040318489, 0.04342959448695183, -0.007839079946279526, 0.03841958940029144, 0.0372023805975914, 0.02700146846473217, 0.0132737522944808, 0.004040902014821768, 0.016149435192346573, -0.034632980823516846, -0.03085939586162567, 0.046753253787755966, -0.05709370598196983, 0.01277568656951189, 0.018043560907244682, 0.009622822515666485, -0.0032432510051876307, -0.026989175006747246, -0.03448445349931717, 0.013858159072697163, -0.019295593723654747, -0.03924603387713432, 0.06740372627973557, -0.04412923753261566, 0.02219916693866253, 0.00563108129426837, -0.004748519975692034, -0.018783660605549812, -0.046357326209545135, -0.01304448302835226, -0.04256124794483185, -0.03404629975557327, 0.012158378958702087, -0.009528710506856441, -0.009488394483923912, -0.03913578391075134, 0.002569090574979782, 0.03993314877152443, -0.01447251159697771, -0.0449986606836319, -0.012892039492726326, 0.010495870374143124, -0.004836794920265675, 0.010801050812005997, 0.0424952395260334, -0.007250642869621515, -0.03148989751935005, -0.04979793727397919, 0.08927997201681137, 0.04259613901376724, 0.042670536786317825, 0.04923325404524803, -0.00406753970310092, 0.013292991556227207, -0.04928458854556084, 0.018311096355319023, 0.013517551124095917, -0.049330729991197586, 0.0019262493588030338, 0.003312169574201107, -0.06511375308036804, 0.03536743298172951, 0.04340781271457672, -0.044085726141929626, -0.007345206569880247, 0.07844521850347519, 0.016101298853754997, -0.07458721101284027, -0.0119416369125247, 0.05081454664468765, -0.033674001693725586, 0.0052276188507676125, 0.02086077444255352, -0.01831083372235298, 0.03370622545480728, -0.02137807011604309, -0.016085822135210037, -0.04627377539873123, 0.03091525100171566, -0.018215807154774666, -0.02995598502457142, 0.028507601469755173, 0.019339002668857574, -0.02782188355922699, 0.017528565600514412, -0.004943253938108683, -0.07290610671043396, -0.052499428391456604, -0.020700091496109962, 0.015313606709241867, -0.06680907309055328, 0.05590960383415222, 0.05308915302157402, 0.015517055056989193, 0.014632897451519966, 0.021846668794751167, -0.07290632277727127, 0.024754460901021957, 0.03561120852828026, 0.02113085240125656, 0.0039644562639296055, -0.03923535346984863, -0.021582886576652527, -0.006462837569415569, -0.00011727321543730795, 0.021535350009799004, 0.02180614322423935, -0.0067053670063614845, -0.023797085508704185, -0.023387663066387177, 0.051688052713871, 0.014732868410646915, -0.008181283250451088, -0.013901572674512863, 0.07292503118515015, 0.04066687822341919, -0.009861527010798454, -0.022116607055068016, 0.001468934933654964, 0.03021419234573841, -0.029982754960656166, -0.022287756204605103, -0.018640536814928055, 0.018104860559105873, -0.0329909473657608, -0.006327821873128414, 0.0015992483822628856, 0.027952052652835846, -0.001436833175830543, -0.011422906070947647, 0.0445220023393631, -0.008093999698758125, -0.09538547694683075, 0.03518768027424812, -0.01822851598262787, -0.02008717693388462, -0.004732436966150999, -0.013233077712357044, 0.0019046759698539972, 0.06470025330781937, 0.03677976131439209, -0.01655251532793045, 0.06170089915394783, -0.07074438035488129, -0.05069790035486221, 0.01335950568318367, -0.024622779339551926, 0.013952846638858318, 0.00016247238090727478, -0.00312716793268919, 0.05518771708011627, -0.02509148046374321, -0.030063828453421593, 0.02448040060698986, -0.0081552192568779, 0.04710092023015022, -0.017608344554901123, 0.043566230684518814, -0.020197216421365738, -0.055162813514471054, -0.016644451767206192, -0.047542352229356766, 0.0386602021753788, 0.05278238281607628, 0.027588505297899246, -0.0420173816382885, -0.03105594962835312, -0.04780832305550575, -0.023468876257538795, -0.01688285358250141, -0.053895819932222366, 0.0028435231652110815, 0.008733612485229969, 0.07943785190582275, 0.0651092529296875, -0.03607381507754326, 0.003863151418045163, -0.010106348432600498, -0.023727353662252426, -0.0019936787430197, -0.06216869503259659, 0.004401789978146553, -0.016631726175546646, 0.02780870907008648, 0.040233075618743896, 0.008267464116215706, -0.025723477825522423, 0.028671419247984886]\n"
     ]
    }
   ],
   "source": [
    "from langchain_chroma import Chroma\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "vector = embeddings.embed_query(\"What is the main topic of the document?\")\n",
    "print(\"Vector:\", vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75fa6c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore= Chroma.from_documents(\n",
    "    documents=docs, embedding=GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac3bf798",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "\n",
    "retrieved_docs = retriever.invoke(\"What is the main topic of the document?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba411366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(retrieved_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5560d6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "of machine learning is increasingly extensive. On the other \n",
      "hand, with the advancement of science and technology, \n",
      "graphics have been the an indispensable medium of \n",
      "information transmission, and image processing technology is \n",
      "also booming. However, the traditional image processing \n",
      "technology, more or less has some defects, this paper \n",
      "introduces machine learning into image processing, and \n",
      "studies the image processing technology based on machine \n",
      "learning. This paper summarizes the current popular image \n",
      "processing technology, compares various image technology in \n",
      "detail, and explains the limitations of each image processing \n",
      "method. In addition, on the basis of image processing, this \n",
      "paper introduces machine learning algorithm, applies \n",
      "convolution neural network to feature extraction of image \n",
      "processing, and carries out simulation test. In the test, we \n",
      "select voc2007 dataset for image segmentation, Imagenet \n",
      "dataset for target detection, cifar100 dataset for image\n"
     ]
    }
   ],
   "source": [
    "print(retrieved_docs[1].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e260d70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    temperature=0.1, max_output_tokens=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52446bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt=(\n",
    "    \"You are a helpful assistant that answers questions based on the provided context. \"\n",
    "    \"If you don't know the answer, just say that you don't know. \"\n",
    "    \"Don't try to make up an answer.\"\n",
    "    \"\\n\\n\"\n",
    "    \"Context: {context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a0aab885",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60491d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: The main topic is the application of machine learning, specifically deep learning, in image processing, focusing on image segmentation, classification, and target detection.  The document discusses the limitations of traditional image processing, the advantages of using machine learning, and presents results from experiments using various datasets (VOC2007, ImageNet, CIFAR100).\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain.invoke({\"input\": \"What is the main topic of the document?\"})\n",
    "print(\"Response:\", response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6975a545",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
